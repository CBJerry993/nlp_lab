{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn, optim\n",
    "import random\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 训练数据\n",
    "text = \"I like dog i like cat i like animal dog cat animal apple cat dog like dog fish milk like dog \\\n",
    "cat eyes like i like apple apple i hate apple i movie book music like cat dog hate cat dog like\"\n",
    "\n",
    "# 参数设置\n",
    "EMBEDDING_DIM = 2  # 词向量维度\n",
    "PRINT_EVERY = 1000  # 可视化频率\n",
    "EPOCHS = 1000  # 训练的轮数\n",
    "BATCH_SIZE = 5  # 每一批训练数据大小\n",
    "N_SAMPLES = 3  # 负样本大小\n",
    "WINDOW_SIZE = 5  # 周边词窗口大小\n",
    "FREQ = 0  # 词汇出现频率\n",
    "DELETE_WORDS = False  # 是否删除部分高频词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 文本预处理\n",
    "def preprocess(text, FREQ):\n",
    "    text = text.lower()\n",
    "    text = text.replace('\"', \"\").replace('.', '').replace(',', '').replace('!', '').replace('-', '').replace('/', '')\n",
    "    words = text.split()\n",
    "    # 去除低频词\n",
    "    word_counts = Counter(words)\n",
    "    trimmed_words = [word for word in words if word_counts[word] > FREQ]\n",
    "    return trimmed_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = preprocess(text, FREQ)\n",
    "# 构建词典\n",
    "vocab = set(words)\n",
    "vocab2int = {w: c for c, w in enumerate(vocab)}\n",
    "int2vocab = {c: w for c, w in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42, 13)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words),len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'animal': 0,\n",
       " 'cat': 1,\n",
       " 'music': 2,\n",
       " 'fish': 3,\n",
       " 'hate': 4,\n",
       " 'dog': 5,\n",
       " 'book': 6,\n",
       " 'eyes': 7,\n",
       " 'apple': 8,\n",
       " 'like': 9,\n",
       " 'i': 10,\n",
       " 'milk': 11,\n",
       " 'movie': 12}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab2int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'animal',\n",
       " 1: 'cat',\n",
       " 2: 'music',\n",
       " 3: 'fish',\n",
       " 4: 'hate',\n",
       " 5: 'dog',\n",
       " 6: 'book',\n",
       " 7: 'eyes',\n",
       " 8: 'apple',\n",
       " 9: 'like',\n",
       " 10: 'i',\n",
       " 11: 'milk',\n",
       " 12: 'movie'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int2vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将文本转化为数值\n",
    "int_words = [vocab2int[w] for w in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10,\n",
       " 9,\n",
       " 5,\n",
       " 10,\n",
       " 9,\n",
       " 1,\n",
       " 10,\n",
       " 9,\n",
       " 0,\n",
       " 5,\n",
       " 1,\n",
       " 0,\n",
       " 8,\n",
       " 1,\n",
       " 5,\n",
       " 9,\n",
       " 5,\n",
       " 3,\n",
       " 11,\n",
       " 9,\n",
       " 5,\n",
       " 1,\n",
       " 7,\n",
       " 9,\n",
       " 10,\n",
       " 9,\n",
       " 8,\n",
       " 8,\n",
       " 10,\n",
       " 4,\n",
       " 8,\n",
       " 10,\n",
       " 12,\n",
       " 6,\n",
       " 2,\n",
       " 9,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 9]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算单词频次\n",
    "int_word_counts = Counter(int_words)\n",
    "total_count = len(int_words)\n",
    "word_freqs = {w: c / total_count for w, c in int_word_counts.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Counter({10: 6,\n",
       "          9: 9,\n",
       "          5: 7,\n",
       "          1: 6,\n",
       "          0: 2,\n",
       "          8: 4,\n",
       "          3: 1,\n",
       "          11: 1,\n",
       "          7: 1,\n",
       "          4: 2,\n",
       "          12: 1,\n",
       "          6: 1,\n",
       "          2: 1}),\n",
       " 42)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_word_counts,total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{10: 0.14285714285714285,\n",
       " 9: 0.21428571428571427,\n",
       " 5: 0.16666666666666666,\n",
       " 1: 0.14285714285714285,\n",
       " 0: 0.047619047619047616,\n",
       " 8: 0.09523809523809523,\n",
       " 3: 0.023809523809523808,\n",
       " 11: 0.023809523809523808,\n",
       " 7: 0.023809523809523808,\n",
       " 4: 0.047619047619047616,\n",
       " 12: 0.023809523809523808,\n",
       " 6: 0.023809523809523808,\n",
       " 2: 0.023809523809523808}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_freqs # values 合计=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 去除出现频次高的词汇\n",
    "if DELETE_WORDS:\n",
    "    t = 1e-5\n",
    "    prob_drop = {w: 1 - np.sqrt(t / word_freqs[w]) for w in int_word_counts}\n",
    "    train_words = [w for w in int_words if random.random() < (1 - prob_drop[w])]  # 随机取句子\n",
    "else:\n",
    "    train_words = int_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 单词分布\n",
    "word_freqs = np.array(list(word_freqs.values()))\n",
    "unigram_dist = word_freqs / word_freqs.sum()\n",
    "noise_dist = torch.from_numpy(unigram_dist ** 0.75 / np.sum(unigram_dist ** 0.75))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.14285714, 0.21428571, 0.16666667, 0.14285714, 0.04761905,\n",
       "       0.0952381 , 0.02380952, 0.02380952, 0.02380952, 0.04761905,\n",
       "       0.02380952, 0.02380952, 0.02380952])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.14285714, 0.21428571, 0.16666667, 0.14285714, 0.04761905,\n",
       "       0.0952381 , 0.02380952, 0.02380952, 0.02380952, 0.04761905,\n",
       "       0.02380952, 0.02380952, 0.02380952])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1306, 0.1770, 0.1466, 0.1306, 0.0573, 0.0963, 0.0341, 0.0341, 0.0341,\n",
       "        0.0573, 0.0341, 0.0341, 0.0341], dtype=torch.float64)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noise_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10,\n",
       " 9,\n",
       " 5,\n",
       " 10,\n",
       " 9,\n",
       " 1,\n",
       " 10,\n",
       " 9,\n",
       " 0,\n",
       " 5,\n",
       " 1,\n",
       " 0,\n",
       " 8,\n",
       " 1,\n",
       " 5,\n",
       " 9,\n",
       " 5,\n",
       " 3,\n",
       " 11,\n",
       " 9,\n",
       " 5,\n",
       " 1,\n",
       " 7,\n",
       " 9,\n",
       " 10,\n",
       " 9,\n",
       " 8,\n",
       " 8,\n",
       " 10,\n",
       " 4,\n",
       " 8,\n",
       " 10,\n",
       " 12,\n",
       " 6,\n",
       " 2,\n",
       " 9,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 9]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_batches = len(words) // BATCH_SIZE  # 训练的batches数\n",
    "n_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = words[:n_batches * BATCH_SIZE]  # 分n_batches批"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'like', 'dog', 'i', 'like']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = words[0:0 + BATCH_SIZE]\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取目标词汇\n",
    "def get_target(words, idx, WINDOW_SIZE):\n",
    "    target_window = np.random.randint(1, WINDOW_SIZE + 1)\n",
    "    start_point = idx - target_window if (idx - target_window) > 0 else 0\n",
    "    end_point = idx + target_window\n",
    "    targets = set(words[start_point:idx] + words[idx + 1:end_point + 1])\n",
    "    return list(targets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['like', 'i', 'dog']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_target(batch, 3, WINDOW_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx=0\n",
    "batch_x, batch_y = [], []\n",
    "batch = words[idx:idx + BATCH_SIZE]  # ['i', 'like', 'dog', 'i', 'like']\n",
    "for i in range(len(batch)):\n",
    "    x = batch[i]\n",
    "    y = get_target(batch, i, WINDOW_SIZE)\n",
    "    batch_x.extend([x] * len(y))\n",
    "    batch_y.extend(y)  # 每个 batch_x, batch_y (['i', 'i'], ['like', 'dog'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['i', 'i', 'like', 'like', 'dog', 'dog', 'i', 'i', 'like'], 9)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_x,len(batch_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['like', 'dog', 'i', 'dog', 'like', 'i', 'like', 'dog', 'i'], 9)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_y,len(batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(20, 2)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_embed = nn.Embedding(20, 2)\n",
    "in_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 2])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_embed.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6618,  0.0574],\n",
       "        [-0.7599, -0.1682],\n",
       "        [-0.3031, -0.6998],\n",
       "        [ 0.3837,  0.3814],\n",
       "        [-0.9982,  0.7549],\n",
       "        [ 0.2456,  0.8541],\n",
       "        [ 0.7077, -0.5567],\n",
       "        [-0.8463, -0.4360],\n",
       "        [-0.6380,  0.6013],\n",
       "        [-0.5156, -0.2961],\n",
       "        [ 0.1760, -0.0384],\n",
       "        [-0.6878,  0.3729],\n",
       "        [-0.1921, -0.8806],\n",
       "        [ 0.5869, -0.7867],\n",
       "        [-0.4817,  0.8569],\n",
       "        [ 0.5214, -0.7104],\n",
       "        [ 0.5345, -0.1481],\n",
       "        [-0.2768, -0.2358],\n",
       "        [ 0.7539, -0.6228],\n",
       "        [-0.2884, -0.5124]])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_embed.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1081, -0.2417],\n",
       "        [ 0.0288,  0.8138],\n",
       "        [-0.0376, -0.8579],\n",
       "        [ 0.4140, -0.0272],\n",
       "        [-0.8545,  0.0154],\n",
       "        [-0.0079, -0.3677],\n",
       "        [ 0.3269,  0.4030],\n",
       "        [ 0.1853, -0.5385],\n",
       "        [ 0.9017, -0.8948],\n",
       "        [-0.1547,  0.1846],\n",
       "        [-0.5386, -0.0622],\n",
       "        [ 0.5384,  0.8612],\n",
       "        [ 0.9927, -0.8090],\n",
       "        [ 0.8339,  0.1430],\n",
       "        [ 0.4584, -0.7878],\n",
       "        [-0.8090,  0.2035],\n",
       "        [-0.3417, -0.8058],\n",
       "        [-0.5695, -0.3639],\n",
       "        [ 0.0519,  0.9526],\n",
       "        [-0.1952, -0.5951]])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_embed.weight.data.uniform_(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = torch.Tensor([0, 10, 3, 0]) # create a Tensor of weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1306, 0.1770, 0.1466, 0.1306, 0.0573, 0.0963, 0.0341, 0.0341, 0.0341,\n",
       "        0.0573, 0.0341, 0.0341, 0.0341], dtype=torch.float64)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noise_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'i', 'like', 'like', 'dog', 'dog', 'i', 'i', 'like']"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['like', 'dog', 'i', 'dog', 'like', 'i', 'like', 'dog', 'i']"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "words=train_words[:n_batches * BATCH_SIZE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10,\n",
       " 9,\n",
       " 5,\n",
       " 10,\n",
       " 9,\n",
       " 1,\n",
       " 10,\n",
       " 9,\n",
       " 0,\n",
       " 5,\n",
       " 1,\n",
       " 0,\n",
       " 8,\n",
       " 1,\n",
       " 5,\n",
       " 9,\n",
       " 5,\n",
       " 3,\n",
       " 11,\n",
       " 9,\n",
       " 5,\n",
       " 1,\n",
       " 7,\n",
       " 9,\n",
       " 10,\n",
       " 9,\n",
       " 8,\n",
       " 8,\n",
       " 10,\n",
       " 4,\n",
       " 8,\n",
       " 10,\n",
       " 12,\n",
       " 6,\n",
       " 2,\n",
       " 9,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 1]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx=0\n",
    "batch_x, batch_y = [], []\n",
    "# 如果传入的是train_words则是用Int表示。后面的备注同！\n",
    "batch = words[idx:idx + BATCH_SIZE]  # ['i', 'like', 'dog', 'i', 'like']\n",
    "for i in range(len(batch)):\n",
    "    x = batch[i]\n",
    "    y = get_target(batch, i, WINDOW_SIZE)\n",
    "    batch_x.extend([x] * len(y))\n",
    "    batch_y.extend(y)  # 每个 batch_x, batch_y (['i', 'i'], ['like', 'dog'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([10, 9, 9, 9, 5, 5, 10, 10, 10, 9, 9], [9, 9, 10, 5, 9, 10, 9, 10, 5, 10, 5])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_x,batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_words, target_words = batch_x,batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, targets = torch.LongTensor(input_words), torch.LongTensor(target_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([11])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_embed = nn.Embedding(13, 2)\n",
    "out_embed = nn.Embedding(13, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([11])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([11, 2])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_vectors = in_embed(inputs)\n",
    "input_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([11])"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([13])"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noise_dist.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([12, 10,  3,  9, 11,  5, 11,  1, 10,  9,  4,  2,  2,  6,  1,  7,  2,  0,\n",
       "          2,  3, 12,  4,  2,  0,  3,  2,  0,  0,  1,  1,  7,  1,  9]),\n",
       " torch.Size([33]))"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noise_words = torch.multinomial(noise_dist, 11 * 3, replacement=True)\n",
    "noise_words,noise_words.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([11, 3, 2])"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noise_vectors = out_embed(noise_words).view(11,3,2)\n",
    "noise_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([11, 2])"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_vectors = input_vectors.view(11,2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'output_vectors' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-189-cf3a06b6c5b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moutput_vectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'output_vectors' is not defined"
     ]
    }
   ],
   "source": [
    "output_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "embedding(): argument 'indices' (position 2) must be Tensor, not list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-192-f4cc08da15e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0moutput_vectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout_embed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m         return F.embedding(\n\u001b[1;32m    113\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   1482\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1483\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1484\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: embedding(): argument 'indices' (position 2) must be Tensor, not list"
     ]
    }
   ],
   "source": [
    "\n",
    "output_vectors = out_embed(target_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'output_words' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-191-5627bceee0f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moutput_words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'output_words' is not defined"
     ]
    }
   ],
   "source": [
    "output_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([11, 2, 1])"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_vectors=input_vectors.view(11,1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([11, 1, 2])"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([11, 1, 1])"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_loss = torch.bmm(output_vectors, input_vectors).sigmoid().log()\n",
    "out_loss.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([11])"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_loss.squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_loss = torch.bmm(noise_vectors.neg(), input_vectors).sigmoid().log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_loss = noise_loss.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1079, -0.4302, -1.0979],\n",
       "        [-0.7239, -1.1712, -0.4102],\n",
       "        [-1.1712, -0.8422, -0.4848],\n",
       "        [-0.7239, -0.3641, -0.6064],\n",
       "        [-0.2998, -2.6692, -0.3717],\n",
       "        [-4.7493, -0.2998, -0.3206],\n",
       "        [-2.7477, -1.0979, -0.1079],\n",
       "        [-0.2689, -2.7477, -1.1097],\n",
       "        [-1.0979, -2.7477, -1.1097],\n",
       "        [-0.7805, -0.8422, -0.8422],\n",
       "        [-0.2338, -0.8422, -0.7239]], grad_fn=<SqueezeBackward0>)"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noise_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'noise_loss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-8c907979a6c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnoise_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'noise_loss' is not defined"
     ]
    }
   ],
   "source": [
    "noise_loss.sum(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.14285714, 0.21428571, 0.16666667, 0.14285714, 0.04761905,\n",
       "       0.0952381 , 0.02380952, 0.02380952, 0.02380952, 0.04761905,\n",
       "       0.02380952, 0.02380952, 0.02380952])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.14285714, 0.21428571, 0.16666667, 0.14285714, 0.04761905,\n",
       "       0.0952381 , 0.02380952, 0.02380952, 0.02380952, 0.04761905,\n",
       "       0.02380952, 0.02380952, 0.02380952])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.1306, 0.1770, 0.1466, 0.1306, 0.0573, 0.0963, 0.0341, 0.0341, 0.0341,\n",
       "         0.0573, 0.0341, 0.0341, 0.0341], dtype=torch.float64),\n",
       " torch.Size([13]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noise_dist,noise_dist.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([22])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.multinomial(noise_dist, 2 * 11, replacement=True).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
